import datetime
import os
import shutil
import json
import numpy as np
from sklearn.model_selection import train_test_split
from tqdm import tqdm
from PIL import Image, ImageDraw

# --- CONFIGURATION ---
ORIGINAL_DATA_DIR = "data"
PREPROCESSED_DATA_DIR = "data_preprocessed"
TRAIN_RATIO = 0.85
RANDOM_STATE = 42

def gather_all_data():
    all_images = []
    all_annotations = []
    master_categories = []

    print("--- Gathering all data from original source ---")
    # Process train, valid, and test to gather all available data
    for dset_name in ["train", "valid", "test"]:
        ann_file_path = os.path.join(ORIGINAL_DATA_DIR, dset_name, "_annotations.coco.json")
        if not os.path.exists(ann_file_path):
            continue

        with open(ann_file_path, 'r') as f:
            coco_data = json.load(f)

        # Store images with their original source path for later copying
        for img in coco_data['images']:
            img['source_path'] = os.path.join(ORIGINAL_DATA_DIR, dset_name, img['file_name'])
            all_images.append(img)
            
        all_annotations.extend(coco_data['annotations'])

        # Use the first category list found as the master list
        if not master_categories and 'categories' in coco_data:
            master_categories = coco_data['categories']

    # Create a stable mapping from original category ID to a 1-based index
    master_categories.sort(key=lambda x: x['id'])
    category_map = {cat['id']: i + 1 for i, cat in enumerate(master_categories)}

    print(f"Found a total of {len(all_images)} images and {len(all_annotations)} annotations.")
    print(f"Master categories: {[cat['name'] for cat in master_categories]}")
    return all_images, all_annotations, category_map, master_categories

def create_new_splits(all_images):
    image_ids = [img['id'] for img in all_images]
    
    train_ids, val_ids = train_test_split(image_ids, train_size=TRAIN_RATIO, random_state=RANDOM_STATE)
    train_ids, val_ids = set(train_ids), set(val_ids)

    train_imgs = [img for img in all_images if img['id'] in train_ids]
    val_imgs = [img for img in all_images if img['id'] in val_ids]

    print(f"Created new split: {len(train_imgs)} training images, {len(val_imgs)} validation images.")
    return train_imgs, val_imgs

def generate_mask_and_targets(annotations, height, width, category_map):
    combined_mask = np.zeros((height, width), dtype=np.uint8)
    boxes, labels = [], []
    
    # Create an ImageDraw object to draw polygon masks
    mask_img = Image.fromarray(np.zeros((height, width), dtype=np.uint8))
    drawer = ImageDraw.Draw(mask_img)

    for i, ann in enumerate(annotations):
        # Create the instance mask from segmentation polygons
        for seg in ann['segmentation']:
            poly = np.array(seg).reshape(-1, 2)
            # The fill value is the unique instance ID (1-based)
            drawer.polygon([tuple(p) for p in poly], fill=i + 1)
        
        # Extract bounding box and label
        bbox = ann['bbox']
        boxes.append([bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]]) # to x1,y1,x2,y2
        labels.append(category_map[ann['category_id']])

    # Convert the drawn image back to a numpy array
    combined_mask = np.array(mask_img)
    return combined_mask, np.array(boxes, dtype=np.float32), np.array(labels, dtype=np.int64)

def save_coco_json(images, annotations, categories, file_path):
    os.makedirs(os.path.dirname(file_path), exist_ok=True)

    info_block = {
        "description": "Saba Ripeness Dataset (Custom Split)",
        "url": "",
        "version": "1.0",
        "year": datetime.date.today().year,
        "contributor": "Generated by preprocessing script",
        "date_created": datetime.datetime.now(datetime.timezone.utc).isoformat(' ')
    }

    licenses_block = [{
        "url": "https://creativecommons.org/licenses/by/4.0/",
        "id": 0,
        "name": "CC BY 4.0"
    }]

    coco_format = {
        "info": info_block,
        "licenses": licenses_block,
        "images": images,
        "annotations": annotations,
        "categories": categories
    }

    with open(file_path, 'w') as f:
        json.dump(coco_format, f)
    print(f"Saved new annotation file to {file_path}")

def process_and_save_set(set_name, image_list, all_annotations, category_map, master_categories):
    output_dir = os.path.join(PREPROCESSED_DATA_DIR, set_name)
    os.makedirs(os.path.join(output_dir, 'images'), exist_ok=True)
    os.makedirs(os.path.join(output_dir, 'masks'), exist_ok=True)
    os.makedirs(os.path.join(output_dir, 'targets'), exist_ok=True)

    # Create a lookup dictionary for faster annotation access
    anns_by_img_id = {img['id']: [] for img in image_list}
    for ann in all_annotations:
        if ann['image_id'] in anns_by_img_id:
            anns_by_img_id[ann['image_id']].append(ann)

    print(f"\n--- Processing and saving '{set_name}' set ---")
    for img_info in tqdm(image_list, desc=f"Processing {set_name}"):
        # 1. Copy original image
        if not os.path.exists(img_info['source_path']):
            print(f"Warning: Image file not found {img_info['source_path']}. Skipping.")
            continue
        shutil.copy(img_info['source_path'], os.path.join(output_dir, 'images', img_info['file_name']))
        
        # 2. Get annotations for this image
        img_anns = anns_by_img_id.get(img_info['id'], [])
        if not img_anns:
            continue

        # 3. Generate mask and targets
        mask_array, boxes, labels = generate_mask_and_targets(
            img_anns, img_info['height'], img_info['width'], category_map
        )
        
        # 4. Save mask and targets
        mask_filename = os.path.splitext(img_info['file_name'])[0] + '.png'
        Image.fromarray(mask_array).save(os.path.join(output_dir, 'masks', mask_filename))
        
        target_filename = os.path.splitext(img_info['file_name'])[0] + '.npz'
        target_path = os.path.join(output_dir, 'targets', target_filename)
        np.savez(target_path, boxes=boxes, labels=labels)

    set_image_ids = {img['id'] for img in image_list}
    set_annotations = [ann for ann in all_annotations if ann['image_id'] in set_image_ids]
    ann_file_path = os.path.join(output_dir, '_annotations.coco.json')
    save_coco_json(image_list, set_annotations, master_categories, ann_file_path)

def run_full_preprocessing():
    if os.path.exists(PREPROCESSED_DATA_DIR):
        print(f"Pre-processed data directory '{PREPROCESSED_DATA_DIR}' already exists.")
        print("Delete the directory to re-run preprocessing.")
        return

    all_images, all_annotations, category_map, master_categories = gather_all_data()

    train_imgs, val_imgs = create_new_splits(all_images)
    
    process_and_save_set('train', train_imgs, all_annotations, category_map, master_categories)
    process_and_save_set('valid', val_imgs, all_annotations, category_map, master_categories)

    print("\n--- Preprocessing complete! ---")
    print(f"All data has been correctly split and saved to '{PREPROCESSED_DATA_DIR}'.")

if __name__ == "__main__":
    run_full_preprocessing()